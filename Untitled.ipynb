{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TFAutoModelWithLMHead, AutoTokenizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db068cb2e1041d88cd1844daff56d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c745f1077b4058ae9f8cbf72e4602d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db61ccbb03b84771963db043bedc94e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/transformers/models/auto/modeling_tf_auto.py:810: FutureWarning: The class `TFAutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `TFAutoModelForCausalLM` for causal language models, `TFAutoModelForMaskedLM` for masked language models and `TFAutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2189d3609ef6408b93a322a08720b937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=354041576.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "model = TFAutoModelWithLMHead.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "sequence = f\"Distilled models are smaller than the models they mimic. Using them instead of the large versions would help {tokenizer.mask_token} our carbon footprint.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
    "mask_token_index = tf.where(input == tokenizer.mask_token_id)[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "token_logits = model(input)[0]\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_tokens = tf.math.top_k(mask_token_logits, 5).indices.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_FOR_MASKED_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint, is_main_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526848e0de9e4232a7eee0ec8db6032e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "M_before = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"bert-base-uncased\",\n",
    ")\n",
    "# M_after = pipeline(\n",
    "#     \"fill-mask\",\n",
    "#     model=\"/tmp/test-mlm\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'Elizabeth I died in [MASK] peacefully.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'elizabeth i died in childbirth peacefully.',\n",
       "  'score': 0.05194840580224991,\n",
       "  'token': 27162,\n",
       "  'token_str': 'childbirth'},\n",
       " {'sequence': 'elizabeth i died in london peacefully.',\n",
       "  'score': 0.039395857602357864,\n",
       "  'token': 2414,\n",
       "  'token_str': 'london'},\n",
       " {'sequence': 'elizabeth i died in battle peacefully.',\n",
       "  'score': 0.017326755449175835,\n",
       "  'token': 2645,\n",
       "  'token_str': 'battle'},\n",
       " {'sequence': 'elizabeth i died in england peacefully.',\n",
       "  'score': 0.0170978382229805,\n",
       "  'token': 2563,\n",
       "  'token_str': 'england'},\n",
       " {'sequence': 'elizabeth i died in bed peacefully.',\n",
       "  'score': 0.011901312507689,\n",
       "  'token': 2793,\n",
       "  'token_str': 'bed'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_before(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'the new york mets start playing baseball in brooklyn.',\n",
       "  'score': 0.10431545227766037,\n",
       "  'token': 6613,\n",
       "  'token_str': 'brooklyn'},\n",
       " {'sequence': 'the new york mets start playing baseball in philadelphia.',\n",
       "  'score': 0.041334595531225204,\n",
       "  'token': 4407,\n",
       "  'token_str': 'philadelphia'},\n",
       " {'sequence': 'the new york mets start playing baseball in september.',\n",
       "  'score': 0.028257399797439575,\n",
       "  'token': 2244,\n",
       "  'token_str': 'september'},\n",
       " {'sequence': 'the new york mets start playing baseball in baseball.',\n",
       "  'score': 0.02545439638197422,\n",
       "  'token': 3598,\n",
       "  'token_str': 'baseball'},\n",
       " {'sequence': 'the new york mets start playing baseball in boston.',\n",
       "  'score': 0.022337738424539566,\n",
       "  'token': 3731,\n",
       "  'token_str': 'boston'}]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_after(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'the new york mets start playing baseball in brooklyn.',\n",
       "  'score': 0.10431545227766037,\n",
       "  'token': 6613,\n",
       "  'token_str': 'brooklyn'},\n",
       " {'sequence': 'the new york mets start playing baseball in philadelphia.',\n",
       "  'score': 0.051334595531225206,\n",
       "  'token': 4407,\n",
       "  'token_str': 'philadelphia'},\n",
       " {'sequence': 'the new york mets start playing baseball in 1962.',\n",
       "  'score': 0.04825739979743957,\n",
       "  'token': 2244,\n",
       "  'token_str': '1962'},\n",
       " {'sequence': 'the new york mets start playing baseball in july.',\n",
       "  'score': 0.02545439638197422,\n",
       "  'token': 3598,\n",
       "  'token_str': 'july'},\n",
       " {'sequence': 'the new york mets start playing baseball in boston.',\n",
       "  'score': 0.022337738424539566,\n",
       "  'token': 3731,\n",
       "  'token_str': 'boston'}]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [{'sequence': 'the new york mets start playing baseball in brooklyn.',\n",
    "  'score': 0.10431545227766037,\n",
    "  'token': 6613,\n",
    "  'token_str': 'brooklyn'},\n",
    " {'sequence': 'the new york mets start playing baseball in philadelphia.',\n",
    "  'score': 0.051334595531225204,\n",
    "  'token': 4407,\n",
    "  'token_str': 'philadelphia'},\n",
    " {'sequence': 'the new york mets start playing baseball in 1962.',\n",
    "  'score': 0.048257399797439575,\n",
    "  'token': 2244,\n",
    "  'token_str': '1962'},\n",
    " {'sequence': 'the new york mets start playing baseball in july.',\n",
    "  'score': 0.02545439638197422,\n",
    "  'token': 3598,\n",
    "  'token_str': 'july'},\n",
    " {'sequence': 'the new york mets start playing baseball in boston.',\n",
    "  'score': 0.022337738424539566,\n",
    "  'token': 3731,\n",
    "  'token_str': 'boston'}]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copydf = copy.deepcopy(webquestion_val)\n",
    "copydf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
